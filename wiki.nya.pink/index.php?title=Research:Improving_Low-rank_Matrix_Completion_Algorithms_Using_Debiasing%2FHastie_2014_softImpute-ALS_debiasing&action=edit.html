<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>View source for Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing - Lab Journal Wiki</title>
<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing","wgTitle":"Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing","wgCurRevisionId":303,"wgRevisionId":0,"wgArticleId":27,"wgIsArticle":!1,"wgIsRedirect":!1,"wgAction":"edit","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgBreakFrames":!0,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":
"Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing","wgRelevantArticleId":27,"wgRequestId":"762c848d6eaf99fb04c3786c","wgCSPNonce":!1,"wgIsProbablyEditable":!1,"wgRelevantPageIsProbablyEditable":!1,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0};RLSTATE={"site.styles":"ready","noscript":"ready","user.styles":"ready","user":"ready","user.options":"ready","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","ext.scite.styles":"ready","ext.smw.style":"ready","ext.smw.tooltip.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.smw.style","ext.smw.table.styles","smw.factbox","mediawiki.action.edit.collapsibleFooter","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.searchSuggest","ext.scite.styles","ext.scite.tooltip","skins.vector.js"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="load.php%3Flang=en&amp;modules=ext.scite.styles|ext.smw.style|ext.smw.tooltip.styles&amp;only=styles&amp;skin=vector.css"/>
<link rel="stylesheet" href="load.php%3Flang=en&amp;modules=mediawiki.legacy.commonPrint,shared|mediawiki.skinning.interface|skins.vector.styles&amp;only=styles&amp;skin=vector.css"/>
<script async="" src="load.php%3Flang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="generator" content="MediaWiki 1.34.2"/>
<meta name="robots" content="noindex,nofollow"/>
<link rel="alternate" type="application/rdf+xml" title="Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing" href="./index.php%3Ftitle=Special:ExportRDF%252FResearch:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;xmlmime=rdf"/>
<link rel="shortcut icon" href="favicon.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="opensearch_desc.php" title="Lab Journal Wiki (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="api.php%3Faction=rsd"/>
<!--[if lt IE 9]><script src="/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Research_Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing_Hastie_2014_softImpute-ALS_debiasing rootpage-Research_Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing skin-vector action-edit">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">View source for Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing</h1>
	
	<div id="bodyContent" class="mw-body-content">
		
		<div id="contentSub">‚Üê <a href="wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html" title="Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing">Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing</a></div>
		
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="./index.php%3Ftitle=Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;action=edit.html#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="./index.php%3Ftitle=Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;action=edit.html#p-search">Jump to search</a>
		<div id="mw-content-text"><p>You do not have permission to edit this page, for the following reason:
</p>
<div class="permissions-errors">
<p>The action you have requested is limited to users in the group: <a href="https://wiki.nya.pink/index.php?title=Lab_Journal_Wiki:Users&amp;action=edit&amp;redlink=1" class="new" title="Lab Journal Wiki:Users (page does not exist)">Users</a>.
</p>
</div><hr />
<p>You can view and copy the source of this page.
</p><textarea readonly="" accesskey="," id="wpTextbox1" cols="80" rows="25" style="" class="mw-editfont-monospace" lang="en" dir="ltr" name="wpTextbox1">==Previous work==

I am mostly using the algorithm described in Hastie et al. [[CiteRef::hastie2014matrix]]. There are two other papers ([[CiteRef::jain2012lowrank]] and [[CiteRef::hardt2013understanding]]) in which the problem is similar enough so that it can be debiased in a similar fashion. The reason to study them is that they provide different convergence guarantees each. For now, can stick to Hastie et al. algorithm.

TODO: add links: &lt;ref>https://arxiv.org/abs/1312.0925&lt;/ref>, &lt;ref>https://arxiv.org/abs/1212.0467&lt;/ref>.

==Definitions==

I will use notation similar to Hastie et al. paper to minimize confusion.

:&lt;math>P_\Omega(X)_{ij} = X_{ij}\text{ if }{ij} \in \Omega, 0\text{ otherwise}&lt;/math>
:&lt;math>P_\Omega(X)_{ij} = X_{ij}\text{ if }{ij} \notin \Omega, 0\text{ otherwise}&lt;/math>
:&lt;math>X\text{ is the original data matrix}&lt;/math>
:&lt;math>M\text{ and }A, B \text{ are optimization variables}&lt;/math>
:&lt;math>||X||_F\text{ is the Frobenious norm of matrix X}&lt;/math>
:&lt;math>||X||_*\text{ is the nuclear norm of matrix X}&lt;/math>

==Optimization problems==

Hastie et al. essentially try to solve a convex optimization problem &lt;xr id="eq:convex-sing-val-min" /> by instead looking for a solution for a non-convex optimization problem &lt;xr id="eq:non-convex-frob-min" />. It turns out that these two problems actually have the same solution, as is shown in their paper.

:&lt;equation id="eq:convex-sing-val-min" shownumber>
&lt;math>
\begin{aligned}
&amp; \underset{M}{\text{minimize}}
&amp; &amp; H(M) := \frac{1}{2}||P_\Omega(X-M)|_{F}^2 + \lambda ||M||_*
\end{aligned}
\quad
\text{(convex)}
&lt;/math>
&lt;/equation>

:&lt;equation id="eq:non-convex-frob-min" shownumber>
&lt;math>
\begin{aligned}
&amp; \underset{A,B}{\text{minimize}}
&amp; &amp; F(A,B) := \frac{1}{2}||P_\Omega(X-AB^T)||_{F}^2 + \frac{\lambda}{2}||A||_{F}^2 + \frac{\lambda}{2}||B||_{F}^2
\end{aligned}
\quad
\text{(non-convex)}
&lt;/math>
&lt;/equation>

==softImpute-ALS==

===Surrogate functions===

Hastie et al. define majorizers &lt;xr id="eq:Q_A_def" /> and &lt;xr id="eq:Q_B_def" />. Furthermore, they show that &lt;math>Q_A(Z_1|A,B) \geq F(Z_1,B)&lt;/math>, and &lt;math>Q_B(Z_2|A,B) \geq F(A,Z_2)&lt;/math>.

:&lt;equation id="eq:Q_A_def" shownumber>
&lt;math>
\begin{aligned}
Q_A(Z_1|A,B) := \frac{1}{2}||P_\Omega(X-Z_1B^T)+P_\Omega^\bot(AB^T-Z_1B^T)||_F^2 + \frac{\lambda}{2}||Z_1||_F^2 + \frac{\lambda}{2}||B||_F^2
\end{aligned}
&lt;/math>
&lt;/equation>

:&lt;equation id="eq:Q_B_def" shownumber>
&lt;math>
\begin{aligned}
Q_B(Z_2|A,B) := \frac{1}{2}||P_\Omega(X-AZ_2^T)+P_\Omega^\bot(AB^T-AZ_2^T)||_F^2 + \frac{\lambda}{2}||A||_F^2 + \frac{\lambda}{2}||Z_2||_F^2
\end{aligned}
&lt;/math>
&lt;/equation>

It's a good idea to compare these two with

&lt;math>
\begin{aligned}
F(A,B) := \frac{1}{2}||P_\Omega(X-AB^T)||_{F}^2 + \frac{\lambda}{2}||A||_{F}^2 + \frac{\lambda}{2}||B||_{F}^2
\end{aligned}
&lt;/math>

Since it's central to their proof, we should also re-state proof of connection between these surrogate functions and the objective function of the non-convex problem.

'''Lemma''': &lt;math>Q_A(Z_1|A,B) \geq F(Z_1,B)&lt;/math>, and &lt;math>Q_B(Z_2|A,B) \geq F(A,Z_2)&lt;/math>

'''Proof''':
Consider the function &lt;math>g(AB^T):= \frac{1}{2}||P_\Omega(X-AB^T)||_F^2&lt;/math> which is the training error as a function of the outer-product &lt;math>Z=AB^T&lt;/math>, and observe that for any &lt;math>Z, \hat{Z}&lt;/math> we have:

&lt;math>
g(Z) \leq \frac{1}{2}||P_\Omega(X-Z)+P_\Omega^\bot(\hat{Z}-Z)||_F^2 = \frac{1}{2}||(P_\Omega(X)+P_\Omega^\bot(\hat{Z}))-Z||_F^2
&lt;/math>

The equality is achieved if &lt;math>Z = \hat{Z}&lt;/math>

Also notice that essentially it doesn't matter at all what we put in the perpendicular part of the sum. I.e. we can take any arbitrary matrix &lt;math>H&lt;/math> and add &lt;math>P_\Omega^\bot(H)&lt;/math> inside &lt;math>g&lt;/math> without changing the outcome of this lemma. This will be useful later.

'''QED'''

===Alternative subspace minimization scheme===

To minimize problem &lt;xr id="eq:non-convex-frob-min" /> they then propose an alternative minimization scheme where they repeatedly fix $A$ or $B$ and optimize for the other variable. They call the algorithm softImpute-ALS. This algorithm, in the form most convenient for theoretical analysis is given in Algorithm &lt;xr id="alg:softImpute-ALS"/>.

&lt;definition id="alg:softImpute-ALS" shownumber>
'''Algorithm (softImpute-ALS)''':
* '''Inputs:''' Data matrix &lt;math>X&lt;/math>, initial iterates &lt;math>A_0&lt;/math> and &lt;math>B_0&lt;/math>, and &lt;math>k = 0&lt;/math>.
* '''Outputs:''' &lt;math>(A^*,B^*)&lt;/math> an estimate of the minimizer of Problem &lt;xr id="eq:non-convex-frob-min" />

* '''Repeat until Convergence:'''
# &lt;math>k \gets k + 1&lt;/math>
# &lt;math>X^* \gets P_\Omega(X) + P_\Omega^\bot(AB^T)=P_\Omega(X-AB^T)+AB^T&lt;/math>
# &lt;math>A \gets X^*B(B^TB+\lambda I)^{-1}=\text{argmin}_{Z_1}Q_A(Z_1|A,B)&lt;/math>
# &lt;math>X^* \gets P_\Omega(X) + P_\Omega^\bot(AB^T)=P_\Omega(X-AB^T)+AB^T&lt;/math>
# &lt;math>B \gets X^{*T}A(A^TA+\lambda I)^{-1}=\text{argmin}_{Z_2}Q_B(Z_2|A,B)&lt;/math>
&lt;/definition>

==Debiased softImpute-ALS==

Hence, in our version of the algorithm, it makes sense to re-define the surrogate functions to account for debiasing.

===Surrogate functions===

Again, let's re-state the objective function:

:&lt;math>
F(A,B) := \frac{1}{2}||P_\Omega(X-AB^T)||_{F}^2 + \frac{\lambda}{2}||A||_{F}^2 + \frac{\lambda}{2}||B||_{F}^2
&lt;/math>

And now, we modify the surrogate functions so that Hastie et al. proofs still work:

:&lt;equation id="eq:Q_A_def_deb" shownumber>
&lt;math>
Q_A^*(Z_1|A,B) := \frac{1}{2}||P_\Omega(X-Z_1B^T)+P_\Omega^\bot(AB^T-Z_1B^T)\circ\frac{1}{K}||_F^2 + \frac{\lambda}{2}||Z_1||_F^2 + \frac{\lambda}{2}||B||_F^2
&lt;/math>
&lt;/equation>


:&lt;equation id="eq:Q_B_def_deb" shownumber>
&lt;math>
Q_B^*(Z_2|A,B) := \frac{1}{2}||P_\Omega(X-AZ_2^T)+P_\Omega^\bot(AB^T-AZ_2^T)\circ\frac{1}{K}||_F^2 + \frac{\lambda}{2}||A||_F^2 + \frac{\lambda}{2}||Z_2||_F^2
&lt;/math>
&lt;/equation>

Notice that it's still true that &lt;math>Q_A^*(Z_1|A,B) \geq F(Z_1,B)&lt;/math>, and &lt;math>Q_B^*(Z_2|A,B) \geq F(A,Z_2)&lt;/math>.

====Important properties of surrogate functions====
* &lt;math>Q_A^*(Z_1|A,B) \geq F(Z_1,B)&lt;/math>, and &lt;math>Q_B^*(Z_2|A,B) \geq F(A,Z_2)&lt;/math>
* &lt;math>Q_A^*(A|A,B)=F(A,B)&lt;/math>, and &lt;math>Q_B^*(B|A,B) = F(A,B)&lt;/math>
* We can iteratively minimize each of &lt;math>Q_B&lt;/math> and &lt;math>Q_A&lt;/math> to try to find a minimum of &lt;math>F&lt;/math>. We don't know if it's a global minimum, but at least we know that the algorithm does not diverge. We also know that it reaches an &lt;math>\epsilon&lt;/math>-bubble of a stationary point in &lt;math>O(\frac{1}{\epsilon})&lt;/math> iterations. Also there is an easy check if the solution is indeed a global minimum. Alternatively, solution can be used as a warm start for an algorithm with better guarantees.

\begin{figure}
    \includegraphics[width=12cm]{ubcdiss-master/both_surrogate.png}
    \caption{Properties of surrogate functions, illustrated. Correction: $Q$ and $F$ should be convex if we only look at one variable at a time. This is actually kind of similar to Newton's method}
    
    \label{fig:both_surrogate}
\end{figure}

\begin{figure}
    \includegraphics[width=12cm]{ubcdiss-master/2-iter.png}
    \caption{Illustration of one iteration of the algorithm. Again note that $Q$'s and $F$ should be convex along the $A$ and $B$ axes (but not necessarily along other axes).}
    
    \label{fig:2-iter}
\end{figure}


===Algorithm===

Algorithm essentially remains the same:

\begin{algorithm}
\caption{\texttt{Debiased softImpute-ALS}}
\begin{algorithmic}[1]
\State \textbf{Inputs:} Data matrix $X$, initial iterates $A_0$ and $B_0$, and $k = 0$.
\State \textbf{Outputs:} $(A^*,B^*)$ an estimate of the minimizer of Problem &lt;xr id="eq:non-convex-frob-min" />
\State
\State \textbf{Repeat until Convergence}
\State $k \gets k + 1$

\State $X^* \gets P_\Omega(X) + P_\Omega^\bot(AB^T)\circ\frac{1}{K}$
and $B^* \gets P_\Omega(B)+P_\Omega^\bot(B)\circ\frac{1}{K}$

\State $A \gets X^*B^*(B^{*T}B^*+\lambda I)^{-1}=\text{argmin}_{Z_1}Q_A^*(Z_1|A,B)$

\State $X^* \gets P_\Omega(X) + P_\Omega^\bot(AB^T)\circ\frac{1}{K}$
and $A^* \gets P_\Omega(A)+P_\Omega^\bot(A)\circ\frac{1}{K}$

\State $B \gets X^{*T}A^*(A^{*T}A^*+\lambda I)^{-1}=\text{argmin}_{Z_2}Q_B^*(Z_2|A,B)$
\end{algorithmic} \label{alg:softImpute-ALS-deb}
\end{algorithm}

\begin{lemm}
Derivation of $Q_A^*(Z_1|A,B)$ and $Q_B^*(Z_2|A,B)$ minimizers.
\end{lemm}

\begin{proof}

Let's begin with $Q_A^*$, since the other one is identical.

It is useful to re-write the insides of $Q_A^*$ in the following form:

\begin{equation}  \label{eq:Q_A_deb_insides}
\begin{aligned}
P_\Omega(X-Z_1B^T)+P_\Omega^\bot(AB^T-Z_1B^T)\circ\frac{1}{K} = \\ =
P_\Omega(X)
+P_\Omega^\bot(AB^T)\circ\frac{1}{K}
-P_\Omega(Z_1B^T)
-P_\Omega^\bot(Z_1B^T)\circ\frac{1}{K}
\end{aligned}
\end{equation}

Define $X^* := P_\Omega(X) + P_\Omega^\bot(AB^T)\circ\frac{1}{K}$. Then we get $X^*-P_\Omega(Z_1B^T)-P_\Omega^\bot(Z_1B^T)\circ\frac{1}{K}$ from the above equation. Finally, we get $X^* 
- Z_1 ( P_\Omega(B^T)+P_\Omega^\bot(B^T)\circ\frac{1}{K})$

Thus, we re-write $Q_A^*$ as:
\begin{equation}  \label{eq:Q_A_def_deb_compact}
\begin{aligned}
Q_A^*(Z_1|A,B) =
\frac{1}{2}||X^* - Z_1 (P_\Omega(B^T)+P_\Omega^\bot(B^T)\circ\frac{1}{K})||_F^2
+ \frac{\lambda}{2}||Z_1||_F^2
+ \frac{\lambda}{2}||B||_F^2
\end{aligned}
\end{equation}

For convinience, define $B^* := P_\Omega(B)+P_\Omega^\bot(B)\circ\frac{1}{K}$. Then, even simpler form is:

Thus, we re-write $Q_A^*$ as:
\begin{equation}  \label{eq:Q_A_def_deb_compact2}
\begin{aligned}
Q_A^*(Z_1|A,B) =
\frac{1}{2}||X^* - Z_1 B^{*T}||_F^2
+ \frac{\lambda}{2}||Z_1||_F^2
+ \frac{\lambda}{2}||B||_F^2
\end{aligned}
\end{equation}

Now compute gradient ($Q_A^*$ is a function of $Z_1$):

\begin{equation}  \label{eq:Q_A_def_deb_compact_der}
\begin{aligned}
\nabla Q_A^*(Z_1|A,B) = (X^* - Z_1 B^{*T})(-B^*)+ \lambda Z_1
\end{aligned}
\end{equation}

Equating it to zero, we get that $Z_1 = X^*B^*(B^{*T}B^*+\lambda I)^{-1}$

Note that later we would see that Hastie et al. give convergence speed guarantees in terms of bounds $\ell^U$ and $\ell^L$ in
$\ell^U \bm{I} \succeq B^TB \succeq \ell^L \bm{I}$ and 
$\ell^U \bm{I} \succeq A^TA \succeq \ell^L \bm{I}$. Thus, if we can show that $A^*$ and $B^*$ have tighter bounds compared to $A$ and $B$, we would prove that our algorithm converges to a stationary point faster than vanilla softImpute-ALS.
\end{proof}

For completeness, let's prove that iterates of debiased softImpute-ALS decrease the objective function monotonically, just like the vanilla version:

\begin{theorem}
Let ${(A_k, B_k)}$ be the iterates generated by the debiased softImpute-ALS. The function values are monotonically decreasing,
$$
F(A_k,B_k) \geq F(A_{k+1}, B_k) \geq F(A_{k+1}, B_{k+1}), k \geq 1.
$$
\end{theorem}

\begin{proof}
Proof is identical to Hastie et. al's. We use the fact that
$$
F(A_{k+1},B_k) \leq
Q_A^*(A_{k+1}|A_k,B_k) =
\text{min}_{Z_1}Q_A^*(Z_1|A_k,B_k) \leq
Q_A^*(A_k|A_k,B_k) = 
F(A_k,B_k)$$
\end{proof}

==Loewner order (bounds on eigenvalues)==

&lt;math>\ell^U \mathbf{I} \succeq B^TB \succeq \ell^L \mathbf{I}&lt;/math> and 
&lt;math>\ell^U \mathbf{I} \succeq A^TA \succeq \ell^L \mathbf{I}&lt;/math>
basically give a bound on the smallest and largest eigenvalues of &lt;math>B^TB&lt;/math> and &lt;math>A^TA&lt;/math>. See [[wikipedia:Loewner order|Loewner order]].

Let's go:

:&lt;math>B = P_\Omega(B) + P_\Omega^\bot(B)&lt;/math>
:&lt;math>B^* = P_\Omega(B) + P_\Omega^\bot(B)\circ \frac{1}{K}&lt;/math>

Then:

:&lt;math>
B^T B =
(P_\Omega(B)^T + P_\Omega(B)^T)(P_\Omega(B) + P_\Omega(B))
&lt;/math>

and

:&lt;math>
B^{*T} B^* =
(P_\Omega(B)^T + P_\Omega(B)^T \circ \frac{1}{K^T})(P_\Omega(B) + P_\Omega(B) \circ \frac{1}{K})
&lt;/math>

So now we just want to show that distribution of eigenvalues of the second quantity is narrower than the first one.

Another way to express &lt;math>B^*&lt;/math> is as:

&lt;math>B^*=
P_\Omega(B) + P_\Omega^\bot(B) - P_\Omega^\bot(B) + P_\Omega^\bot(B)\circ \frac{1}{K} =
B + (I - \frac{1}{K})\circ P_\Omega^\bot(B)
&lt;/math>

But wait, what is exactly &lt;math>P_\Omega(B)&lt;/math>, considering that &lt;math>B&lt;/math> might not even be a square matrix?

==Splitting the projection operator==

In the algorithm we have a term:

:&lt;math>
P_\Omega(X-Z_1B^T)+P_\Omega^\bot(AB^T-Z_1B^T)\circ\frac{1}{K}
&lt;/math>

Which can be re-written as:

:&lt;math>
P_\Omega(X)
+P_\Omega^\bot(AB^T)\circ\frac{1}{K}
-P_\Omega(Z_1B^T)
-P_\Omega^\bot(Z_1B^T)\circ\frac{1}{K}
&lt;/math>

We are trying to solve for &lt;math>Z_1&lt;/math>, hence we are interested in the last two terms:

:&lt;math>
P_\Omega(Z_1B^T) + P_\Omega^\bot(Z_1B^T)\circ\frac{1}{K}
&lt;/math>

Idea: Perhaps we can compute expected value of &lt;math>Q_A^*(Z_1|A,B)&lt;/math> and minimize it?
If only we could show that &lt;math>\text{argmin}&lt;/math> for the expected value is smaller than &lt;math>Q_A^*(A|A,B)&lt;/math>, Hastie's arguments should still work.

===Reiterating on the function we want to minimize===

The function we want to see minimized is:

:&lt;math>
Q_A^*(Z_1|A,B) := \frac{1}{2}||P_\Omega(X-Z_1B^T)+P_\Omega^\bot(AB^T-Z_1B^T)\circ\frac{1}{K}||_F^2 + \frac{\lambda}{2}||Z_1||_F^2 + \frac{\lambda}{2}||B||_F^2
&lt;/math>

In order to solve it, we might want to factor out &lt;math>Z_1&lt;/math>.

Alternatively, we might just express it in Einstein notation. But, first let's simplify things a bit by defining:

:&lt;math>X^* := P_\Omega(X) + P_\Omega^\bot(AB^T)\circ\frac{1}{K}&lt;/math>

Then:

:&lt;math>
Q_A^*(Z_1|A,B) =
\frac{1}{2}||X^* - (P_\Omega(Z_1B^T)+P_\Omega^\bot(Z_1B^T)\circ\frac{1}{K})||_F^2
+ \frac{\lambda}{2}||Z_1||_F^2
+ \frac{\lambda}{2}||B||_F^2
&lt;/math>

Now, the last two terms are not very hard to differentiate, so let's focus on the first one:

:&lt;math>
T(Z) := \frac{1}{2}||X^* - (P_\Omega(Z B^T)+P_\Omega^\bot(Z B^T)\circ\frac{1}{K})||_F^2
&lt;/math>

&lt;div style="background-color: plum; border-style: solid; margin: 10px; padding: 10px; display:inline-block">

Then:

:&lt;math>
T(Z) := \frac{1}{2}\sum_{ik}(X^*_{ik} - (P_\Omega(Z B^T)_{ik}+P_\Omega^\bot(Z B^T)_{ik}\frac{1}{K_{ik}}))^2
&lt;/math>

Split the sum:

:&lt;math>
T(Z) := \frac{1}{2}\sum_{ik \in \Omega}(X^*_{ik} - (Z B^T)_{ik})^2
+ \frac{1}{2}\sum_{ik \not \in \Omega}(X^*_{ik} - (Z B^T)_{ik} \frac{1}{K_{ik}}))^2
&lt;/math>

Expand the matrix multiplication:

:&lt;math>
T(Z) := \frac{1}{2}\sum_{ik \in \Omega}(X^*_{ik} - \sum_j Z_{ij} B^T_{jk})^2
+ \frac{1}{2}\sum_{ik \not \in \Omega}(X^*_{ik} - \sum_j Z_{ij} B^T_{jk} \frac{1}{K_{ik}}))^2
&lt;/math>

Differentiate (WIP):

:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} := \frac{1}{2}\sum_{ik \in \Omega}(X^*_{ik} - \sum_j Z_{ij} B^T_{jk})^2
+ \frac{1}{2}\sum_{ik \not \in \Omega}(X^*_{ik} - \sum_j Z_{ij} B^T_{jk} \frac{1}{K_{ik}}))^2
&lt;/math>

&lt;/div>

But wait, we can go another way. Consider &lt;math>T(Z)=\frac{1}{2}||X^*-M(Z)||_F^2&lt;/math>,
where &lt;math>M(Z) := P_\Omega(Z B^T)+P_\Omega^\bot(Z B^T)\circ\frac{1}{K}&lt;/math>. Then:

:&lt;math>
\frac{\partial T(Z)}{\partial Z} = (X^* - M(Z)) \frac{\partial M(Z)}{\partial Z}
&lt;/math>.

So, essentially, we only need to compute &lt;math>\frac{\partial M(Z)}{\partial Z}&lt;/math>.

:&lt;math>M(Z)_{ik} = \begin{cases} 
(ZB^T)_{ik} &amp; ik \in \Omega \\
(ZB^T)_{ik}\frac{1}{K_{ik}} &amp; ik \not \in \Omega
\end{cases}
&lt;/math>

Expand the matrix multiplication:

:&lt;math>M(Z)_{ik} = \begin{cases} 
\sum_j Z_{ij} B^T_{jk} &amp; ik \in \Omega \\
\sum_j Z_{ij} B^T_{jk}\frac{1}{K_{ik}} &amp; ik \not \in \Omega
\end{cases}
&lt;/math>

And now we finally differentiate:

:&lt;math>\frac{\partial T(Z)_{ik}}{\partial Z_{ab}}&lt;/math>

So it's order 4 tensor. Need to consider the cases. 
We essentially have a product of two options: &lt;math>ik \in \Omega&lt;/math>,
&lt;math>ik \not \in \Omega&lt;/math>, and &lt;math>a=i&lt;/math>, &lt;math>a \not =i&lt;/math>:

{| class="wikitable"
|-
|                                 || &lt;math>a=i&lt;/math> || &lt;math>a \not =i&lt;/math>
|-
| &lt;math>ik \in \Omega&lt;/math>      ||          ... || ...
|-
| &lt;math>ik \not \in \Omega&lt;/math> ||          ... || ...
|}

Say, for example, &lt;math>ik \in \Omega&lt;/math>, then:

:&lt;math>
\frac{\partial T(Z)_{ik}}{\partial Z_{ab}} =
\frac{\partial\sum_j Z_{ij} B^T_{jk}}{\partial{Z_{ab}}}
&lt;/math>

Then, if &lt;math>a \not = i&lt;/math>, the above is zero. Otherwise (if &lt;math>a = i&lt;/math>), we need &lt;math>b=j&lt;/math>:

:&lt;math>
\frac{\partial T(Z)_{ik}}{\partial Z_{ab}} = B^T_{bk}
&lt;/math>

Approach for the case &lt;math>ik \not \in \Omega&lt;/math> is identical. This gives us the following table:

{| class="wikitable"
|-
|                                 ||          &lt;math>a=i&lt;/math>             || &lt;math>a \not =i&lt;/math>
|-
| &lt;math>ik \in \Omega&lt;/math>      ||      &lt;math>B^T_{bk}&lt;/math>            || 0
|-
| &lt;math>ik \not \in \Omega&lt;/math> || &lt;math>B^T_{bk}\frac{1}{K_{ak}}&lt;/math> || 0
|}

We can finally get the complete derivative:

:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} = \sum_{ak \in \Omega}(X^*_{ak} - \sum_j Z_{aj} B^T_{jk})B^T_{bk}
+ \sum_{ak \not \in \Omega}(X^*_{ak} - \sum_j Z_{aj} B^T_{jk} \frac{1}{K_{ak}})B^T_{bk}\frac{1}{K_{ak}}
&lt;/math>

Perhaps we can introduce a "one-dimensional" function &lt;math>\Omega_a&lt;/math>:

:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} = \sum_{k \in \Omega_a}(X^*_{ak} - \sum_j Z_{aj} B^T_{jk})B^T_{bk}
+ \sum_{k \not \in \Omega_a}(X^*_{ak} - \sum_j Z_{aj} B^T_{jk} \frac{1}{K_{ak}})B^T_{bk}\frac{1}{K_{ak}}
&lt;/math>

Now we just need to combine the sums into one sum, and we can apply a regular matrix inversion.

First, let's expand the expression:

:&lt;equation id="eq:expanded-der-TZ" shownumber>
&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} =
\sum_{k \in \Omega_a}X^*_{ak}B^T_{bk} - \sum_{k \in \Omega_a}\sum_j Z_{aj} B^T_{jk}B^T_{bk}
+ \sum_{k \not \in \Omega_a}X^*_{ak}B^T_{bk}\frac{1}{K_{ak}} - \sum_{k \not \in \Omega_a}\sum_j Z_{aj} B^T_{jk} \frac{1}{K_{ak}}B^T_{bk}\frac{1}{K_{ak}}
&lt;/math>
&lt;/equation>

At this point, it seems useful to define another projection operator:
:&lt;math>
P_{\Omega_a}(B^T)_{bk} = \begin{cases} 
B^T_{bk} &amp; k \in \Omega_a \\
0 &amp; k \not \in \Omega_a
\end{cases}
&lt;/math> 

Similarly:
:&lt;math>
P_{\Omega_a^\bot}(B^T)_{bk} = \begin{cases} 
0 &amp; k \in \Omega_a \\
B^T_{bk} &amp; k \not \in \Omega_a
\end{cases}
&lt;/math>

Now, we can rewrite &lt;xr id="eq:expanded-der-TZ" /> as:
:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} =
\sum_{k}X^*_{ak}(P_{\Omega_a}(B^T)_{bk}+P_{\Omega_a^\bot}(B^T)_{bk}\frac{1}{K_{ak}})
- \sum_j Z_{aj}(
    \sum_{k \in \Omega_a} B^T_{jk}B^T_{bk}
  + \sum_{k \not \in \Omega_a} B^T_{jk} B^T_{bk}\frac{1}{K_{ak}^2}
)
&lt;/math>

The second product in the second term (&lt;math>\sum_{k \in \Omega_a} B^T_{jk}B^T_{bk}
+ \sum_{k \not \in \Omega_a} B^T_{jk} B^T_{bk}\frac{1}{K_{ak}^2}&lt;/math>) can then be re-written as:
:&lt;math>
\sum_{k} (P_{\Omega_a}(B^T)_{jk}P_{\Omega_a}(B^T)_{bk}
+ P_{\Omega_a^\bot}(B^T)_{jk} P_{\Omega_a^\bot}(B^T)_{bk}\frac{1}{K_{ak}^2})
&lt;/math>

Is this equivalent to the expression below?
:&lt;math>
\sum_{k} (P_{\Omega_a}(B^T)_{jk}+ P_{\Omega_a^\bot}(B^T)_{jk}\frac{1}{K_{ak}})
(P_{\Omega_a}(B^T)_{bk} + P_{\Omega_a^\bot}(B^T)_{bk}\frac{1}{K_{ak}})
&lt;/math>

Seems like it. Just think about what happens when &lt;math>k \in \Omega&lt;/math> and when &lt;math>k \not \in \Omega&lt;/math>.

We can now define &lt;math>\hat{B}^T_{a,jk}&lt;/math> as:
:&lt;math>\hat{B}^T_{a,jk}=
P_{\Omega_a}(B^T)_{jk}+ P_{\Omega_a^\bot}(B^T)_{jk}\frac{1}{K_{ak}}
&lt;/math>

In this case, we can re-write the derivative as:
:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} =
\sum_{k}X^*_{ak}\hat{B}^T_{a,bk}
- \sum_{k}\sum_j Z_{aj}\hat{B}^T_{a,jk}\hat{B}^T_{a,bk}
&lt;/math>

Also, I think there is an error in my derivation, and in fact, indices of &lt;math>\hat{B}^T&lt;/math> should be switched in some places:
:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} =
\sum_{k}X^*_{ak}\hat{B}^T_{a,kb}
- \sum_{k}\sum_j Z_{aj}\hat{B}^T_{a,jk}\hat{B}^T_{a,kb}
&lt;/math>

Now we can re-write it using Einstein notation to better illustrate what is going on:

:&lt;math>
\frac{\partial T(Z)}{\partial Z_{ab}} =
X^*_{ak} \hat{B}^{kT}_{a,b}
- Z_{aj} \hat{B}^{jT}_{a,k} \hat{B}^{kT}_{a,b}
&lt;/math>

Now, equate it to zero, and fix &lt;math>a&lt;/math>, while combining over all &lt;math>b&lt;/math>'s into a vector:

:&lt;math>
X^*_{a} \hat{B}^{T}_{a} =
Z_{a} \hat{B}^{T}_{a} \hat{B}^{T}_{a}
&lt;/math>

The details of this expression don't seem right. But the general shape seems reasonable. This looks pretty much like ALS. So, we can expect this algorithm to behave better than ALS, but it requires more computations compared to SoftImpute-ALS.

The correct formula probably looks like:
:&lt;math>
X^*_{a} \hat{B}_{a} =
Z_{a}^{T}\hat{B}_{a} \hat{B}_{a}
&lt;/math>

And this gives:
:&lt;math>
Z_{a} = X^*_{a} \hat{B}_{a}\left ( \hat{B}^{T}_{a} \hat{B}_{a} \right )^{-1}
&lt;/math>

Adding &lt;math>\lambda&lt;/math>:
:&lt;math>
Z_{a} = X^*_{a} \hat{B}_{a}\left ( \hat{B}^{T}_{a} \hat{B}_{a} + \lambda I \right )^{-1}
&lt;/math>

TODO: Check this carefully (there's probably an alternative derivation).

==Continuation==
Continues at [[Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing/Debiased_Algorithm]].

==References==

[[Category:Matrix completion]]
</textarea><div class="templatesUsed"></div><p id="mw-returnto">Return to <a href="wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html" title="Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing">Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing</a>.</p>
</div>
		
		<div class="printfooter">Retrieved from "<a dir="ltr" href="wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html">https://wiki.nya.pink/wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing</a>"</div>
		
		<div id="catlinks" class="catlinks catlinks-allhidden" data-mw="interface"></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="smw-tabs smw-factbox"><input id="tab-facts-list" class="nav-tab" type="radio" name="tabs" checked=""/><label id="tab-label-facts-list" for="tab-facts-list" class="nav-label" title="Shows statements and facts that have been created by a user">Facts</label><section id="tab-content-facts-list"><div class="mw-parser-output"><div class="smwfact" style="display:block;"><div class="smwfactboxhead">... more about "<span class=""><a href="wiki/Special:Browse/:Research:Improving-20Low-2Drank-20Matrix-20Completion-20Algorithms-20Using-20Debiasing-2FHastie-202014-20softImpute-2DALS-20debiasing.html" title="Special:Browse/:Research:Improving-20Low-2Drank-20Matrix-20Completion-20Algorithms-20Using-20Debiasing-2FHastie-202014-20softImpute-2DALS-20debiasing">Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing</a></span>"</div><div class="smwrdflink"><span class="rdflink"><a href="wiki/Special:ExportRDF/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing" title="Special:ExportRDF/Research:Improving Low-rank Matrix Completion Algorithms Using Debiasing/Hastie 2014 softImpute-ALS debiasing">RDF feed</a></span></div><div class="smw-table smwfacttable"><div class="smw-table-row"><div class="smw-table-cell smwspecname"><span class="smw-highlighter" data-type="1" data-state="inline" data-title="Property" title="This property is a special property in this wiki."><span class="smwbuiltin"><a href="wiki/Property:Citation_reference.html" title="Property:Citation reference">Citation reference</a></span><span class="smwttcontent">This property is a special property in this wiki.</span></span></div><div class="smw-table-cell smwspecs">hastie2014matrix  <span class="smwsearch"><a href="wiki/Special:SearchByProperty/:Citation-20reference/hastie2014matrix.html" title="Special:SearchByProperty/:Citation-20reference/hastie2014matrix">+</a></span>, jain2012lowrank  <span class="smwsearch"><a href="wiki/Special:SearchByProperty/:Citation-20reference/jain2012lowrank.html" title="Special:SearchByProperty/:Citation-20reference/jain2012lowrank">+</a></span>&#160; and&#160;hardt2013understanding  <span class="smwsearch"><a href="wiki/Special:SearchByProperty/:Citation-20reference/hardt2013understanding.html" title="Special:SearchByProperty/:Citation-20reference/hardt2013understanding">+</a></span></div></div></div></div></div></section></div>
</div>


		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-login"><a href="https://wiki.nya.pink/index.php?title=Special:UserLogin&amp;returnto=Research%3AImproving+Low-rank+Matrix+Completion+Algorithms+Using+Debiasing%2FHastie+2014+softImpute-ALS+debiasing&amp;returntoquery=action%3Dedit" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html" title="View the content page [c]" accesskey="c">Page</a></span></li><li id="ca-talk" class="new"><span><a href="https://wiki.nya.pink/index.php?title=Talk:Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing&amp;action=edit&amp;redlink=1" rel="discussion" title="Discussion about the content page (page does not exist) [t]" accesskey="t">Discussion</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
						<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
							<li id="ca-view" class="collapsible"><span><a href="wiki/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html">Read</a></span></li><li id="ca-viewsource" class="collapsible selected"><span><a href="./index.php%3Ftitle=Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;action=edit.html" title="This page is protected.&#10;You can view its source [e]" accesskey="e">View source</a></span></li><li id="ca-history" class="collapsible"><span><a href="./index.php%3Ftitle=Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;action=history.html" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
						<h3 id="p-cactions-label"><span>More</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>
						<form action="https://wiki.nya.pink/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Search Lab Journal Wiki" title="Search Lab Journal Wiki [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search the pages for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="robots.txt.html" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="robots.txt.html" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-recentchanges"><a href="https://wiki.nya.pink/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-randompage"><a href="wiki/Special:Random.html" title="Load a random page [x]" accesskey="x">Random page</a></li><li id="n-help-mediawiki"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/Help:Contents">Help about MediaWiki</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="wiki/Special:WhatLinksHere/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing.html" title="A list of all wiki pages that link here [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="https://wiki.nya.pink/wiki/Special:RecentChangesLinked/Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing/Hastie_2014_softImpute-ALS_debiasing" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-specialpages"><a href="wiki/Special:SpecialPages.html" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-info"><a href="./index.php%3Ftitle=Research:Improving_Low-rank_Matrix_Completion_Algorithms_Using_Debiasing%252FHastie_2014_softImpute-ALS_debiasing&amp;action=info.html" title="More information about this page">Page information</a></li>				</ul>
							</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://wiki.nya.pink/wiki/Lab_Journal_Wiki:Privacy_policy" title="Lab Journal Wiki:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="https://wiki.nya.pink/wiki/Lab_Journal_Wiki:About" title="Lab Journal Wiki:About">About Lab Journal Wiki</a></li>
								<li id="footer-places-disclaimer"><a href="https://wiki.nya.pink/wiki/Lab_Journal_Wiki:General_disclaimer" title="Lab Journal Wiki:General disclaimer">Disclaimers</a></li>
							</ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-poweredbyico">
						<a href="https://www.mediawiki.org/"><img src="resources/assets/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="resources/assets/poweredby_mediawiki_132x47.png 1.5x, resources/assets/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a><a href="https://www.semantic-mediawiki.org/wiki/Semantic_MediaWiki"><img src="data:image/png;base64,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" alt="Powered by Semantic MediaWiki" class="smw-footer" width="88" height="31"/></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":95});});</script>
</body>
</html>
